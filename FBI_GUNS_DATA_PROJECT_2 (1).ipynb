{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Investigate a Dataset (FBI Gun Data)\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>\n",
    "\n",
    "Introduction \n",
    "\n",
    "This dataset contains the number of FBI firearm background checks initiated through the FBI's National Instant Criminal Background Check System (NICS).The NICS data is used to determine whether a prospective buyer is eligible to buy firearms or explosives. Gun shops call into this system to ensure that each customer does not have a criminal record or isn’t otherwise ineligible to make a purchase. The data has been supplemented with state level data from census.gov.\n",
    "\n",
    "https://www.fbi.gov/services/cjis/nics\n",
    "https://github.com/BuzzFeedNews/nics-firearm-background-checks/blob/master/README.md\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Questions:\n",
    "\n",
    "What state has the highest total of gun registrations?\n",
    "\n",
    "What is the overall trend of gun purchases?\n",
    "\n",
    "What state has the highest guns per capita?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib  inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    "> In this section, I will load in the data, check for cleanliness, and then trim and clean my dataset for analysis. \n",
    "\n",
    "\n",
    "### General Properties\n",
    "\n",
    "\n",
    "The NICS data is found in one sheet of an .xlsx file. It contains the number of firearm checks by month, state, and type.\n",
    "The U.S. census data is found in a .csv file. It contains several variables at the state level. Most variables just have one data point per state (2016), but a few have data for more than one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load your data and print out a few lines. Perform operations to inspect data\n",
    "\n",
    "df_guns = pd.read_excel('gun-data.xlsx')\n",
    "\n",
    "df_us_census = pd.read_csv('U.S. Census Data.csv', sep =',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guns Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_guns.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guns.info()  # this displays a concise summary of the dataframe,\n",
    "                # including the number of non-null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_guns.isnull().sum()  # check for missing value count for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_guns.describe() # check summary statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guns.duplicated().sum() # check for duplicate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_census.head(5) # columns and rows should be swapped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_us_census.info() # 2 columns have nulls, state columns should be floats or ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_us_census['Fact'].unique()  # check unique rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_census['Fact Note'].unique() # this column can be dropped since the information is not useful for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_us_census.duplicated().sum())# check for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **Tip**: Make sure that you keep your reader informed on the steps that you are taking in your investigation. Follow every code cell, or every set of related code cells, with a markdown cell to describe to the reader what was found in the preceding cell(s). Try to make it so that the reader can then understand what they will be seeing in the following cell(s).\n",
    "\n",
    "### Data Cleaning \n",
    "\n",
    "For consistency I'm going to drop states/territories that are not found in both datasets, strip spaces in columns, and convert all columns to lowercase. I'm going to clean and further check the data for missing data, incorrect data types, and duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FBI Guns Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Sales estimates are calculated from handgun, long gun and \n",
    "multiple-gun background checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_guns[\"state\"] = df_guns[\"state\"].str.lower()  #made the state column lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#incorrect data types \n",
    "\n",
    "#timestamps are represented as strings instead of datetime \n",
    "df_guns['month'] = pd.to_datetime(df_guns.month, format= \"%Y-%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking state column \n",
    "\n",
    "df_guns_q1['state'].unique()  # Guam ,Mariana Islands, Puerto Rico, Virgin Islands, District of Columbia aren't in the census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter and drop Guam ,Mariana Islands, Puerto Rico, Virgin Islands, District of Columbia rows since they\n",
    "\n",
    "df_guns.drop = df_guns.query('state != \"guam\"',inplace=True)\n",
    "df_guns.drop = df_guns.query('state != \"mariana islands\"',inplace=True)\n",
    "df_guns.drop = df_guns.query('state != \"puerto rico\"', inplace=True)\n",
    "df_guns.drop = df_guns.query('state != \"virgin islands\"',inplace=True)\n",
    "df_guns.drop = df_guns.query('state != \"district of columbia\"',inplace=True)\n",
    "\n",
    "df_guns['state'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a new df for question 1 to drop columns  - this isnt ideal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guns_q1 = df_guns #making a new df to join with census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/51070985/find-out-the-percentage-of-missing-values-in-each-column-in-the-given-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into month and year\n",
    "#df_guns_q1['year'] = df_guns_q1['month'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data - I wanted to see the percentage of missing data in the guns dataset for every column\n",
    "percent_missing = df_guns_q1.isnull().sum() * 100 / len(df_guns_q1)\n",
    "missing_values = pd.DataFrame({'column_name': df_guns_q1.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guns_q1 = df_guns_q1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop columns with high volume of nulls and for analysis\n",
    "df_guns_q1.drop(['permit','permit_recheck','other','admin','prepawn_handgun','prepawn_long_gun','prepawn_other','redemption_other', 'redemption_handgun','redemption_long_gun','returned_other','rentals_handgun','rentals_long_gun','private_sale_handgun','private_sale_long_gun','private_sale_other','return_to_seller_handgun','return_to_seller_long_gun','return_to_seller_other','returned_handgun','returned_long_gun'], axis=1, inplace=True)\n",
    "\n",
    "df_guns_q1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a histogram of - totals, handgun, and long_gun all seem to be skewed to the right \n",
    "\n",
    "df_guns_q1.hist(figsize=(10,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Cleaning: Census Data\n",
    "\n",
    "● The U.S. census data is found\n",
    "in a .csv file. It contains several\n",
    "variables at the state level. Most\n",
    "variables just have one data\n",
    "point per state (2016), but a few\n",
    "have data for more than one\n",
    "year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_us_census.T #swap columns with rows to join with the FBI guns data # need to figure out where to do this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_census_2 = df_us_census.T\n",
    "df_us_census_2.columns = df_us_census_2.loc['Fact']\n",
    "df_us_census_2.drop(['Fact','Fact Note'],inplace=True)\n",
    "\n",
    "df_us_census_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lowercase and replace commas with _ and remove spaces\n",
    "df_us_census_2.columns = [str(x).lower().replace(',','_').replace(' ','') for x in df_us_census_2.columns]\n",
    "\n",
    "df_us_census_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://knowledge.udacity.com/questions/428050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_census_2.info() # check index to drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns between column index 3 to 86 since we're only going to look at 2016 and 2010 population\n",
    "\n",
    "df_us_census_2.drop(df_us_census_2.iloc[:, 3:86], inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "df_us_census_2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_census_2.head(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/malaklm/solution/blob/master/US%20Census%20data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace commas in dataset to convert to floats #not sure if this will work\n",
    "df_us_census_2.replace({\",\": ''}, regex=True,inplace=True)\n",
    "df_us_census_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert strings to floats \n",
    "df_us_census_2['populationestimates_july1_2016_(v2016)'] = pd.to_numeric(df_us_census_2['populationestimates_july1_2016_(v2016)'],errors= 'coerce',downcast='float')\n",
    "df_us_census_2['populationestimatesbase_april1_2010_(v2016)'] = pd.to_numeric(df_us_census_2['populationestimatesbase_april1_2010_(v2016)'],errors= 'coerce',downcast='float')\n",
    "\n",
    "df_us_census_2.dtypes # check if data type conversion worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_census.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "> **Tip**: Now that you've trimmed and cleaned your data, you're ready to move on to exploration. Compute statistics and create visualizations with the goal of addressing the research questions that you posed in the Introduction section. It is recommended that you be systematic with your approach. Look at one variable at a time, and then follow it up by looking at relationships between variables.\n",
    "\n",
    "What is the overall trend of gun purchases?\n",
    "\n",
    "What state has the highest growth in gun registrations?\n",
    "\n",
    "\n",
    "What state has the highest guns per capita?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 1: What is the overall trend of gun purchases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://seaborn.pydata.org/examples/timeseries_facets.html\n",
    "\n",
    "https://stackoverflow.com/questions/65300109/generating-a-line-graph-using-seaborn-or-matplotlib-with-year-as-hue-month-as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "guns_overtime = df_guns_q1.groupby(['month'])['totals'].sum()\n",
    "\n",
    "\n",
    "overtime_fig= sns.lineplot(data=guns_overtime, palette=\"crest\")\n",
    "overtime_fig.set_title('Total # of Gun Permits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 2: What state has the highest volume of gun registrations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_guns_q1_totals = df_guns_q1.groupby(['state']).sum().sort_values(by='totals', ascending=False).head(5)\n",
    "df_guns_q1_totals\n",
    "\n",
    "\n",
    "# use one without year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.barplot(x =\"state\", y=\"totals\", data=df_guns_q1_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 3: What state had the highest per capita sales in 2016?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the 2010 data\n",
    "guns_2010 = df_guns[df_guns.month == '2010-07']\n",
    "guns_2010.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guns_2010.set_index('state',inplace=True,drop=True)\n",
    "guns_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guns_2010.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_census_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the census and gun data\n",
    "\n",
    "df_us_census_2010 = df_us_census_2['populationestimatesbase_april1_2010_(v2016)']\n",
    "\n",
    "df_us_census_2010.join(guns_2010)\n",
    "df_us_census_2010.to_frame().join(guns_2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_us_census_2010 = pd.Series(df_us_census_2010, index=df_us_census_2010.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_census_2010.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#here doesnt work\n",
    "percapita_2010 = df_us_census_2010['totals']/df_us_census_2010['populationestimatesbase_april1_2010_(v2016)']\n",
    "percapita_2010.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to explore the data to address your additional research\n",
    "#   questions. Add more headers as needed if you have more questions to\n",
    "#   investigate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    "> **Tip**: Finally, summarize your findings and the results that have been performed. Make sure that you are clear with regards to the limitations of your exploration. If you haven't done any statistical tests, do not imply any statistical conclusions. And make sure you avoid implying causation from correlation!\n",
    "\n",
    "> **Tip**: Once you are satisfied with your work, you should save a copy of the report in HTML or PDF form via the **File** > **Download as** submenu. Before exporting your report, check over it to make sure that the flow of the report is complete. You should probably remove all of the \"Tip\" quotes like this one so that the presentation is as tidy as possible. Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
